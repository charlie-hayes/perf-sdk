syntax = "proto3";

// See README.md in this directory for a description of these.
package protocol;
option csharp_namespace = "Couchbase.Grpc.Protocol";
option java_package = "com.couchbase.grpc.sdk.protocol";
option java_multiple_files = true;
option go_package = "github.com/charlie-hayes/perf-sdk/protocol";

import "sdk_commands.proto";
import "grpc_commands.proto";
import "google/protobuf/timestamp.proto";
import "google/protobuf/empty.proto";

service PerformerSdkService {
    // Requests the performer's capabilities.
    rpc performerCapsFetch (PerformerCapsFetchRequest) returns (PerformerCapsFetchResponse);

    // Creates a connection from the performer to a cluster.
    rpc clusterConnectionCreate (ClusterConnectionCreateRequest) returns (ClusterConnectionCreateResponse);

    // Close a particular cluster connection.
    rpc clusterConnectionClose (ClusterConnectionCloseRequest) returns (ClusterConnectionCloseResponse);

    rpc perfRun (PerfRunRequest) returns (stream PerfSingleResult);

    // Request that the performer Echo a string to the performer logs.
    rpc echo (EchoRequest) returns (EchoResponse);

    // Tells the performer to exit.
    rpc exit (ExitRequest) returns (stream google.protobuf.Empty);
}

// When an implementation supports multiple APIs, this enum allows sending which is preferred to be used for a given test.
// This is an abstraction that allows us to test e.g. Java's blocking vs reactive APIs.
//
// Declaration in supportedApis:
//  For implementations with just one API: Only declare DEFAULT.
//  For implementations with separate blocking & async APIs: declare both.
//
// When the performer receives a preferred API:
//  For implementations with just one API: ignore it.
//  For implementations with separate blocking & async APIs: use the appropriate one.
enum API {
    DEFAULT = 0;
    ASYNC = 1;
}

enum ImplementationCaps {
    // Empty enum not allowed
    IMPLEMENTATION_DUMMY = 0;
}

enum PerformerCaps {
    // Support GRPC workload.  It's optional.
    GRPC_TESTING = 0;
}

message PerformerCapsFetchRequest {
}

message PerformerCapsFetchResponse {
    // The capabilities of the implementation-under-test.
    repeated ImplementationCaps implementationCaps = 1;

    // The capabilities of this performer.
    repeated PerformerCaps performerCaps = 2;

    // Human-readable string identifying the performer.  For example, "java".
    string performerUserAgent = 3;

    // The APIs this implementation supports.  This is primarily used to run tests on multiple APIs, so if an implementation
    // only supports one, it should just return one - see comments for `API` for details.
    // If the performer does not return anything, it will be assumed to support just API.DEFAULT.
    repeated API supportedApis = 4;

    // It's crucial we always compare apples-to-apples in the tests, e.g. if anything changes on the performer side that
    // means we can't compare results from it against previous results.
    // Bump this whenever that happens.  (Will also need to force a rerun of tests for this language, since jenkins-sdk
    // won't know it's occurred).
    int32 performerVersion = 5;
}

message ClusterConfig {
    // Used for TLS enabled clusters such as Capella clusters
    bool useTls = 3;
    optional string certPath = 4;
    // todo fill out
}

// Creates a cluster connection, with an optional cluster & transactions configuration.
message ClusterConnectionCreateRequest {
    // The id to use for this connection.
    string clusterConnectionId = 1;

    // Details of the cluster connection.
    string clusterHostname = 2;
    string clusterUsername = 3;
    string clusterPassword = 4;

    optional ClusterConfig clusterConfig = 5;
}

message ClusterConnectionCreateResponse {
}

message ClusterConnectionCloseRequest {
    string clusterConnectionId = 1;
}

message ClusterConnectionCloseResponse {
}

message EchoRequest {
    string message = 1;
    string testName = 2;
}

message EchoResponse {
}

// We may need the flexibility to do various forms of counter, e.g.:
// 1. Aim to do 1m operations across all threads.
// 2. Each thread does 1m operations.
// (1) is the simplest and most useful, so is the only one supported for now.
message CounterGlobal {
    // The performer should initialise the counter at this value, and will generally keep going until the counter reaches 0
    int32 count = 1;
}

message Counter {
    // Each counter gets a unique id (unique to the PerfRunRequest, not globally unique).  The performer will create these on-demand.
    // Each counter is bound to a PerfRunRequest.
    // E.g. concurrent PerfRunRequests both referencing "counter1" should have separate isolated counters.
    string counterId = 1;

    oneof counter {
        CounterGlobal global = 2;
    }
}

message SdkWorkload {
    // The command to run
    // todo make this repeated?
    SdkCommand command = 1;

    // The performer should run this many of `command`
    // todo add performer throughput bounding - aim for 100 ops/sec and see latency
    Counter counter = 2;
}

// Used for meta purposes such as testing GRPC workflow.  Only sent if performer declares support for GRPC_TESTING.
message GrpcWorkload {
    // The command to run
    GrpcCommand command = 1;

    // The performer should run this many of `command`
    Counter counter = 2;
}

// Request the performer runs a particular workload
message Workload {
    oneof workload {
        SdkWorkload sdk = 1;
        GrpcWorkload grpc = 2;
    }
}

enum SdkException {
    // todo - fill these out
    SDK_EXCEPTION_DUMMY = 0;
}

// todo make SdkCommand naming consistent
message SdkOperationResult {
    // todo rename this result
    oneof exception {
        // If the small overhead of creating a full InsertResult is not required (e.g. for performance testing), can
        // return this generic success instead.
        bool success = 1;

        SdkException knownException = 2;

        // If the exception is not represented in SdkException, can return it in raw form here
        string unknownException = 3;

        // In future we will have MutationResult, GetResult, etc. for integration testing
    }
}

// "HorizontalScaling" is an abstraction over there being many forms of concurrency.  The core idea is that the driver
// is trying to increase the parallelism, and it's up to the performer to choose a suitable platform-dependent way to
// do this.
// For some languages that will be threads.  For some, a larger pool of concurrent Future/Promises.  For some,
// forking a new process.
// Whatever is produced (thread, new process), it should run the provided workload in a tight loop.  So essentially
// PerfRunHorizontalScaling is the number of concurrent operations taking place.
// todo rename this to HorizontalScaling
message PerfRunHorizontalScaling {
    // Performer will run these workloads in this 'thread-like', in the specified order.
    repeated Workload workloads = 1;
}

message PerfRunRequest {
    // The previously established cluster connection to use
    string clusterConnectionId = 1;

    // See PerfRunHorizontalScaling for a discussion of this.  Broadly, it's the number of concurrent operations
    // required.
    repeated PerfRunHorizontalScaling horizontalScaling = 2;

    optional PerfRunConfig config = 3;
}

// Controls how the performer streams back results.
// The performer is largely free to do this as it sees fit, though this config message contains some optional hints
// that may help it do so.
// Note that there is no provision for dropping packets currently.  It is expected that the performer (and driver, and
// network) can keep up streaming back results from any workload.
// From testing with the Java implementation:
// - Batching results in PerfBatchedResults increased flowrate by nearly 2 orders of magnitude.
// - Flow control (waiting until the GRPC stream is ready), is possibly essential.  This implies the performer maintain
//   an unbounded write queue.
message PerfRunConfigStreaming {
    // The next two parameters are only mandatory on GrpcWorkloads.  Otherwise they should be regarded as optional
    // hints.  If the performer follows them then it will automatically get what has been tested to most reliably
    // return results.  But it can override them if it has done its own testing and found its own best path to
    // streaming back results.  If going this path, remember to increase the performerVersion field whenever substantially
    // changing how the results are being streamed back, for apples-to-apples comparisons.

    // If present, the performer should stream back PerfBatchedResults, aiming to contain this number of results.
    // The performer can return less elements than this in a batch (so it does not have to wait for a write queue to
    // fill first), but should not return more.
    optional int32 batchSize = 1;

    // Whether the performer should enable flow control.  This will mean different things to different
    // GRPC implementations, but the concept is to only send responses when the GRPC response stream reports itself ready.
    bool flowControl = 2;
}

message PerfRunConfig {
    optional PerfRunConfigStreaming streamingConfig = 1;
}

message PerfBatchedResult {
    repeated PerfSingleResult result = 1;
}

// todo rename result
message PerfSingleResult {
    oneof result {
        // Each SdkCommand should return back one of these results.  There is no requirement for these to be in sorted order - the driver
        // will take care of that.
        PerfSingleOperationResult operationResult = 1;

        // The performer can send back metrics whenever it wishes.  However, due to the way database results are currently
        // joined with the bucket results (which are in one second buckets), it's only useful to send back a maximum of
        // one per second.
        PerfMetricsResult metricsResult = 2;

        // Each GrpcCommand should return back one of these results.  There is no requirement for these to be in sorted order - the driver
        // will take care of that.
        PerfGrpcResult grpcResult = 3;

        PerfBatchedResult batchedResult = 4;
    }
}

// todo PerfSdkCommandResult?
message PerfSingleOperationResult {
    oneof result {
        SdkOperationResult sdkResult = 1;
    }

    // Clocks are hard.  Many OS/platform combinations cannot guarantee nanosecond level precision of a wallclock time,
    // but can provide such precision for elapsed time.
    // So:
    // `elapsedNanos` is intended to be, as precisely as the platform can measure it, the exact time taken by the operation in nanoseconds.
    // Measured from just before sending the operation into the SDK (e.g. after handling any GRPC work), and just after
    // the SDK returns.
    // `initiated` is a wallclock time, used to place this operation into a one second bucket.  This should be as
    // accurate as the platform can provide (often realistically this is only accurate to 10 millis or so).  Hopefully
    // a few operations ending up in the wrong bucket each second will not dramatically impact the results.  It is ok
    // to set `initiated` before the GRPC work, due to the reduced precision.
    // If the operation fails, the performer does not need to set `elapsedNanos` - it will not be used.  However `initiated`
    // must always be sent.
    int64 elapsedNanos = 2;
    google.protobuf.Timestamp initiated = 3;
}

message PerfMetricsResult {
    // A JSON blob that can contain any information the performer likes.  '{"cpu":83}' for example.  It will be written
    // directly into the database.
    string metrics = 1;
    google.protobuf.Timestamp initiated = 2;
}

message PerfGrpcPingResult {
}

// todo move perf stuff into separate file
message PerfGrpcResult {
    oneof result {
        PerfGrpcPingResult pingResult = 1;
    }
}

message ExitRequest {
    string reason = 1;
    int32 exitCode = 2;
}